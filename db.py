# db.py (Supabase-only)
from __future__ import annotations

import os
import json
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

from etl_utils import utc_now_z


def _db_url() -> str:
    url = os.getenv("WEATHER_DB_URL") or os.getenv("DATABASE_URL")
    if not url:
        raise RuntimeError("Missing WEATHER_DB_URL (or DATABASE_URL) for Supabase Postgres.")
    return url


def get_conn():
    url = _db_url()
    try:
        import psycopg  # type: ignore
        return psycopg.connect(url)
    except ImportError:
        import psycopg2  # type: ignore
        return psycopg2.connect(url)


def init_db() -> None:
    # Supabase schema should be created via migrations/001_init.sql
    # This is a lightweight connectivity check.
    conn = get_conn()
    conn.close()


def upsert_location(station: dict) -> None:
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        insert into public.locations (station_id, name, state, timezone, lat, lon, elevation_ft, is_active)
        values (%s,%s,%s,%s,%s,%s,%s,%s)
        on conflict (station_id) do update set
          name=coalesce(excluded.name, public.locations.name),
          state=coalesce(excluded.state, public.locations.state),
          timezone=coalesce(excluded.timezone, public.locations.timezone),
          lat=coalesce(excluded.lat, public.locations.lat),
          lon=coalesce(excluded.lon, public.locations.lon),
          elevation_ft=coalesce(excluded.elevation_ft, public.locations.elevation_ft),
          is_active=coalesce(excluded.is_active, public.locations.is_active)
        """,
        (
            station["station_id"],
            station.get("name"),
            station.get("state"),
            station.get("timezone"),
            station.get("lat"),
            station.get("lon"),
            station.get("elevation_ft"),
            station.get("is_active", True),
        ),
    )

    conn.commit()
    conn.close()


def upsert_observation(
    station_id: str,
    obs_date: str,
    observed_high: float,
    observed_low: float,
    issued_at: Optional[str] = None,
    raw_text: Optional[str] = None,
    source: str = "nws_station_obs",
) -> None:
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        insert into public.observations
          (station_id, date, observed_high, observed_low, issued_at, fetched_at, raw_text, source)
        values (%s,%s::date,%s,%s,%s::timestamptz, now(), %s, %s)
        on conflict (station_id, date) do update set
          observed_high=excluded.observed_high,
          observed_low=excluded.observed_low,
          issued_at=coalesce(excluded.issued_at, public.observations.issued_at),
          fetched_at=now(),
          raw_text=coalesce(excluded.raw_text, public.observations.raw_text),
          source=excluded.source
        """,
        (station_id, obs_date, observed_high, observed_low, issued_at, raw_text, source),
    )

    conn.commit()
    conn.close()


def get_or_create_forecast_run(source: str, issued_at: str, meta: Optional[Dict[str, Any]] = None) -> str:
    meta = meta or {}
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        insert into public.forecast_runs (source, issued_at, meta)
        values (%s, %s::timestamptz, %s::jsonb)
        on conflict (source, issued_at) do update set fetched_at=now()
        returning run_id
        """,
        (source, issued_at, json.dumps(meta)),
    )
    run_id = str(cur.fetchone()[0])

    conn.commit()
    conn.close()
    return run_id


def upsert_forecast_value(
    *,
    run_id: str,
    station_id: str,
    target_date: str,
    kind: str,
    value_f: float,
    lead_hours: Optional[float],
    extras: Optional[Dict[str, Any]] = None,
) -> None:
    extras = extras or {}

    cur_vals = (
        run_id,
        station_id,
        target_date,
        kind,
        value_f,
        lead_hours,
        extras.get("dewpoint_f"),
        extras.get("humidity_pct"),
        extras.get("wind_speed_mph"),
        extras.get("wind_dir_deg"),
        extras.get("cloud_cover_pct"),
        extras.get("precip_prob_pct"),
    )

    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        insert into public.forecasts
          (run_id, station_id, target_date, kind, value_f, lead_hours,
           dewpoint_f, humidity_pct, wind_speed_mph, wind_dir_deg, cloud_cover_pct, precip_prob_pct)
        values
          (%s::uuid,%s,%s::date,%s,%s,%s,%s,%s,%s,%s,%s,%s)
        on conflict (run_id, station_id, target_date, kind) do update set
          value_f=excluded.value_f,
          lead_hours=coalesce(excluded.lead_hours, public.forecasts.lead_hours),
          dewpoint_f=coalesce(excluded.dewpoint_f, public.forecasts.dewpoint_f),
          humidity_pct=coalesce(excluded.humidity_pct, public.forecasts.humidity_pct),
          wind_speed_mph=coalesce(excluded.wind_speed_mph, public.forecasts.wind_speed_mph),
          wind_dir_deg=coalesce(excluded.wind_dir_deg, public.forecasts.wind_dir_deg),
          cloud_cover_pct=coalesce(excluded.cloud_cover_pct, public.forecasts.cloud_cover_pct),
          precip_prob_pct=coalesce(excluded.precip_prob_pct, public.forecasts.precip_prob_pct)
        """,
        cur_vals,
    )

    conn.commit()
    conn.close()


def build_errors_for_date(target_date: str) -> int:
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        select station_id, observed_high, observed_low
        from public.observations
        where date=%s::date
        """,
        (target_date,),
    )
    obs_rows = cur.fetchall()
    if not obs_rows:
        conn.close()
        return 0

    wrote = 0
    for station_id, oh, ol in obs_rows:
        cur.execute(
            """
            select f.run_id, r.source, r.issued_at, f.kind, f.value_f, f.lead_hours
            from public.forecasts f
            join public.forecast_runs r on r.run_id = f.run_id
            where f.station_id=%s and f.target_date=%s::date
            """,
            (station_id, target_date),
        )
        for run_id, source, issued_at, kind, forecast_f, lead_hours in cur.fetchall():
            if forecast_f is None:
                continue
            observed_f = float(oh) if kind == "high" else float(ol)
            error_f = float(forecast_f) - observed_f
            abs_error_f = abs(error_f)
            forecast_id = f"{run_id}|{station_id}|{target_date}|{kind}"

            cur.execute(
                """
                insert into public.forecast_errors
                  (forecast_id, station_id, source, target_date, kind, issued_at, lead_hours,
                   forecast_f, observed_f, error_f, abs_error_f)
                values
                  (%s,%s,%s,%s::date,%s,%s,%s,%s,%s,%s,%s)
                on conflict (forecast_id) do nothing
                """,
                (
                    forecast_id,
                    station_id,
                    source,
                    target_date,
                    kind,
                    issued_at,
                    lead_hours,
                    forecast_f,
                    observed_f,
                    error_f,
                    abs_error_f,
                ),
            )
            wrote += 1

    conn.commit()
    conn.close()
    return wrote


def _percentile(sorted_vals: List[float], p: float) -> float:
    if not sorted_vals:
        return float("nan")
    if len(sorted_vals) == 1:
        return float(sorted_vals[0])
    k = (len(sorted_vals) - 1) * p
    f = int(k)
    c = min(f + 1, len(sorted_vals) - 1)
    if f == c:
        return float(sorted_vals[f])
    d0 = sorted_vals[f] * (c - k)
    d1 = sorted_vals[c] * (k - f)
    return float(d0 + d1)


def update_error_stats(*, window_days: int, station_id: Optional[str] = None) -> None:
    conn = get_conn()
    cur = conn.cursor()

    params: List[Any] = [window_days]
    station_clause = ""
    if station_id:
        station_clause = "and station_id=%s"
        params.append(station_id)

    cur.execute(
        f"""
        select source, kind, error_f, abs_error_f
        from public.forecast_errors
        where target_date >= (now()::date - (%s::int * interval '1 day'))
        {station_clause}
        """,
        params,
    )
    rows = cur.fetchall()

    by: Dict[Tuple[str, str], List[Tuple[float, float]]] = {}
    for source, kind, e, ae in rows:
        if e is None or ae is None:
            continue
        by.setdefault((str(source), str(kind)), []).append((float(e), float(ae)))

    now_ts = utc_now_z()

    for (source, kind), vals in by.items():
        n = len(vals)
        errors = [v[0] for v in vals]
        abs_errors = [v[1] for v in vals]

        bias = sum(errors) / n
        mae = sum(abs_errors) / n
        rmse = (sum((x * x) for x in errors) / n) ** 0.5

        se = sorted(errors)
        p10 = _percentile(se, 0.10)
        p50 = _percentile(se, 0.50)
        p90 = _percentile(se, 0.90)

        cur.execute(
            """
            insert into public.error_stats
              (station_id, source, kind, window_days, n, bias, mae, rmse, p10, p50, p90, last_updated)
            values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s::timestamptz)
            on conflict (station_id, source, kind, window_days) do update set
              n=excluded.n, bias=excluded.bias, mae=excluded.mae, rmse=excluded.rmse,
              p10=excluded.p10, p50=excluded.p50, p90=excluded.p90, last_updated=excluded.last_updated
            """,
            (station_id, source, kind, window_days, n, bias, mae, rmse, p10, p50, p90, now_ts),
        )

    # combined ("both") = mean(MAE_high, MAE_low)
    for source in sorted(set(k[0] for k in by.keys())):
        highs = by.get((source, "high"), [])
        lows = by.get((source, "low"), [])
        if not highs or not lows:
            continue
        mae_high = sum(v[1] for v in highs) / len(highs)
        mae_low = sum(v[1] for v in lows) / len(lows)
        mae_both = (mae_high + mae_low) / 2.0
        n = min(len(highs), len(lows))

        cur.execute(
            """
            insert into public.error_stats
              (station_id, source, kind, window_days, n, mae, last_updated)
            values (%s,%s,'both',%s,%s,%s,%s::timestamptz)
            on conflict (station_id, source, kind, window_days) do update set
              n=excluded.n, mae=excluded.mae, last_updated=excluded.last_updated
            """,
            (station_id, source, window_days, n, mae_both, now_ts),
        )

    conn.commit()
    conn.close()
